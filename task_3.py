# -*- coding: utf-8 -*-
"""Task-3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t8VuKB23_EwKfkUWfRGkPvlI1nIF78eV

# Name: Uthsavi KP

# Task 3:Prediction using Decision Tree Algorithm

#### For the given ‘Iris’ dataset, create the Decision Tree classifier and visualize it graphically.
#### The purpose is if we feed any new data to this classifier, it would be able to predict the right class accordingly.
"""

# Commented out IPython magic to ensure Python compatibility.
# Import the required libraries
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Loading the dataset
df = pd.read_csv("Iris.csv")

# Displaying the first 5 rows
df.head()

# Displaying last 5 rows
df.tail()

# Displaying the information of each column 
df.info()

df.describe()

# Checking for null values
df.isnull().sum()

# Dropping the Id columns as it does not porive us any information
df = df.drop(['Id'],axis=1)

# Dividing the data into attributes and labels
X = df.drop(['Species'],axis=1)
y = df['Species']

X.describe()

# Using seaborn to to display the countplot
import seaborn as sns
plt.figure(figsize=(5,5))
sns.countplot('Species',data=df)

# Visualizing the relationship between each variable using seaborn
plot = sns.pairplot(df, hue ='Species', diag_kind= 'hist', palette='husl')
plot.map_upper(sns.kdeplot, cmap='prism')

# Diving the data into attibutes and labels
X = df.drop(['Species'],axis=1)
y = df['Species']

y.value_counts()

X.describe()

"""# Train Test Split"""

# Splitting the data into traing and testing 
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=555)

y_train.value_counts()

y_test.value_counts()

!pwd

"""# Building the model

## Classifier 1
"""

# Importing the Classifier from sklearn
from sklearn.tree import DecisionTreeClassifier

#Creat decision tree classifier object with max depth 2 and gini
clf1 = DecisionTreeClassifier(criterion="gini",max_depth=2)

#Train decision tree classifier
clf1.fit(X_train,y_train)

#Predict the response for test dataset
y_pred_test = clf1.predict(X_test)

#Predict the response for train dataset
y_pred_train = clf1.predict(X_train)

from sklearn import metrics
from sklearn.metrics import classification_report

#Model accuracy, how often the classifier is correct?
print("Train accuracy:",metrics.accuracy_score(y_train,y_pred_train))

#Model accuracy, how often the classifier is correct?
print("Test accuaracy:",metrics.accuracy_score(y_test,y_pred_test))

# Displaying the Classification report
print(classification_report(y_test,y_pred_test))

"""## Classifier 2"""

#Creat decision tree classifier object with max depth 3 and entropy
clf2 = DecisionTreeClassifier(criterion="entropy",max_depth=3)
clf2.fit(X_train,y_train)
y_pred_train1 = clf2.predict(X_train)
y_pred_test1 = clf2.predict(X_test)

#Model accuracy, how often the classifier is correct?
print("Train accuracy:",metrics.accuracy_score(y_train,y_pred_train1))
print("Test accuaracy:",metrics.accuracy_score(y_test,y_pred_test1))

# Displaying the classification report
print(classification_report(y_test,y_pred_test1))

"""## Classifier 3"""

#Creat decision tree classifier object with max depth 4 and entropy
clf3 = DecisionTreeClassifier(criterion="entropy",max_depth=4)
clf3.fit(X_train,y_train)
y_pred_train2 = clf3.predict(X_train)
y_pred_test2 = clf3.predict(X_test)

#Model accuracy, how often the classifier is correct?
print("Train accuracy:",metrics.accuracy_score(y_train,y_pred_train2))
print("Test accuaracy:",metrics.accuracy_score(y_test,y_pred_test2))

# Displaying the classification report
print(classification_report(y_test,y_pred_test2))

"""Looking at classifier clf3, it is clearly visible that the decision tree classifier with max_depth 4 is overfitting.
Classifer clf2 with  max depth 3 has good accuracy and recall.
So I am selecting clf2.

# **Graphical Representation of Tree**
"""

from sklearn.tree import export_graphviz
from sklearn.externals.six import StringIO
from IPython.display import Image  
import pydotplus

dot_data = StringIO()
export_graphviz(clf2, 
                out_file=dot_data,  
                filled=True, 
                rounded=True,
                special_characters=True,
                feature_names = X.columns,
                class_names=['Iris-setosa','Iris-versicolor','Iris-virginica'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('Iris.png')
Image(graph.create_png())